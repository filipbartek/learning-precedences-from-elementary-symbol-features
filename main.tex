\input{preamble}

\title{Learning Precedences from Simple Symbol Features\thanks{Supported by the ERC Consolidator grant AI4REASON no. 649043 under the EU-H2020 programme and the Czech Science Foundataion project 20-06390Y.}}
\titlerunning{Learning Precedences from Elementary Symbol Features}
\author{Filip B\'{a}rtek \and Martin Suda}
\authorrunning{B\'{a}rtek, Suda}
\institute{Czech Technical University in Prague, Czech Republic}

\begin{document}

\maketitle

\begin{abstract}
A simplification ordering, typically specified by a symbol precedence,
is one of the key parameters of the superposition calculus, contributing
to shaping the search space navigated by a saturation-based \acrlong{atp}.
Thus the choice of a precedence can have a great impact on the prover's performance.
In this work, we design a system for proposing favourable predicate symbol precedences.
The system relies on machine learning to extract the information from
past runs of a theorem prover over a set of problems and random precedences.
Moreover, it uses a small set of simple human-engineered symbol features as the sole
basis for discriminating the symbols. This allows for a direct comparison
with precedence construction heuristics designed by prover developers.
\todo[author=Martin]{Let's add this when we have the results finalized:
Training a linear model converges to ordering the symbols by the number of their occurrences.}
\end{abstract}

\section{Introduction}

Modern saturation-based Automated Theorem Provers (ATPs) such as E \cite{SCV:CADE-2019} and Vampire \cite{Kovacs2013}
use the superposition calculus \cite{Nieuwenhuis2001} as their underlying inference system.
Superposition is built around the paramodulation inference \cite{Robinson1983} crucially
constrained by simplification ordering on terms and literals, which is supplied as a parameter of the calculus.
Each of the two classes of simplification orderings used in practice,
i.e., the Knuth-Bendix Ordering (KBO) \cite{Knuth1983}
and the Lexicographic Path Ordering (LPO) \cite{Kamin1980},
are mainly determined by a pair of \emph{symbol precedences}, permutations of the sets of predicate and function symbols,
respectively.\footnote{
KBO is further parameterized by symbol weights, but our reference implementation in Vampire~\cite{Kovacs2013} 
uses for efficiency reasons only weights equal to one \cite{DBLP:conf/cade/KovacsMV11} and so we do not consider this parameter here.}

While the superposition calculus is known \cite{DBLP:journals/logcom/BachmairG94} to be refutationally complete for any simplification ordering, the choice of the precedences may have a significant impact on how long it takes to solve a given problem.
In a well-known example, prioritizing in the precedence the predicates introduced during the Tseitin transformation of an input formula \cite{Tseitin1983} exposes the corresponding literals to resolution inference during early stages of the proof search,
with the effect of essentially undoing the transformation and thus threatening with an exponential blow-up
the transformation is designed to prevent \cite{Reger2016}.
%
ATPs typically offer a few heuristic schemes for generating the symbol precedences.
For example, the successful \texttt{invfreq} scheme in E \cite{E-manual} orders the symbols by the number of occurrences in the input problem,
prioritizing symbols that occur the least often for early inferences.
Experiments with random precedences have shown that the existing schemes often fail to come close to the optimum precedence \cite{RegerSuda2017}, revealing there is a large potential for further improvements.

In this work, we design a system that, when presented with a First-Order Logic (FOL) problem,
proposes a symbol precedence that will likely lead to solving the problem quickly.
The system relies on the techniques of supervised machine learning and extracts
such theorem-proving knowledge from successful (and unsuccessful) runs of 
the Vampire theorem prover~\cite{Kovacs2013} when run over a variety of FOL problems equipped
with randomly sampled symbol precedences. 
We assume that by learning to solve already solvable problems quickly,
the acquired knowledge will generalize and help solving problems previously out of reach.
% This general assumption is shared with other projects for automatically learning theorem
% proving strategies from previous experience, such as the MaLeS system \cite{DBLP:journals/jar/KuhlweinU15}.
As a first step in a more ambitions project,
we focus here on representing the symbols in a problem by a fixed set of simple human-engineered features
(such as the number the occurrences used by \texttt{invfreq} scheme mentioned above)\footnote{Automatic
feature extraction using neural-networks is planned for future work.}
and, to simplify the experimental setup, we restrict our attention to learning precedences for predicate symbols only.\footnote{
Our theoretical considerations, however, apply equally to learning function symbol precedences.}

Learning to predict good precedences poses several interesting challenges that we address in this work.
First, it is not immediately clear how to characterise a precedence, a permutation of a finite set of symbols,
by a real-valued feature vector to serve as an input for a learning algorithm. 
Additionally, to be able to generalise across problems
we need to do it in a way which does not presuppose a fixed signature size. 
There is also a complication, when sampling different problems,
that some problems may be easy to solve for almost every precedence and others hard.
In theorem proving, running times typically vary considerably.
Finally, even with a regression model ready to predict the prover's performance 
under a particular precedence $\pi$, we still need solve the task of finding 
the ideally optimal precedence $\pi^*$ according to this model.

% Final paragraph, with forward reference, explaines how we tackle the challenges and where it is explained
% 1) preference values
% 2) normalization
% 3) learning to order things

% ze n! je super large -> almost infinite source of data (for non-trivial n)

% ----

% Zastrc nekam dozadu na pozdeji

% - we use abstract time as the basic measure 
% (why not actual time to solve a problem? Unstable, abstract time is machine independent and still correlates well)

% - zmin konkretni stratgie, kterou pouzivame a variujeme v ni pouze predikatovou precendenci
% (vcetne toho, ze funknci precedenci fixujeme na frequency)

\newpage

\section{Introduction}

The most successful \gls{fol} \glspl{atp} are based on superposition calculus,
which is parameterized by simplification term ordering.
Each of the two most commonly used simplification orderings, \gls{kbo} and \gls{lpo},
is in turn parameterized by a pair of symbol precedences:
predicate precedence and function precedence.
Each of these precedences is a permutation of the respective symbols of the problem under consideration.

In this text we limit ourselves to discussion of predicate symbol precedences for the sake of simplicity.
We fix function precedences to use the frequency heuristic.

Given a problem, we look for a predicate \gls{precedence} that leads to a successful and quick proof search.

\Gls{preference-value} of an ordered pair of symbols \((P_0, P_1)\) expresses a penalty associated with ordering the symbol \(P_0\) before the symbol \(P_1\).
Positive value means that ordering \(P_0\) before \(P_1\) is associated with low probability of success.
Negative value means that ordering \(P_0\) before \(P_1\) is associated with high probability of success.
Value close to zero means that the order of symbols \(P_0\) and \(P_1\) has no effect on the probability of success.

\Gls{preference-matrix} is a square matrix populated with preference values of all the pairs of symbols.

For a given symbol precedence,
\gls{order-matrix} \(C\) is a boolean square matrix of size \(n \times n\) where \(n\) is the number of symbols.
\(C_{i, j}\) is true if and only if symbol \(P_i\) precedes symbol \(P_j\) in the precedence.


\section{Architecture}

\subsection{Basic assumptions}

For the discussion that follows in this section,
we assume a fixed \gls{fol} \gls{atp} that uses superposition calculus parameterized by symbol precedence.
While the practical experiments described in \autoref{sec:evaluation} use the \gls{atp} Vampire \cite{Kovacs2013},
the model architecture does not assume a particular \gls{atp}
and is compatible with any superposition-based \gls{atp} such as Vampire or E \cite{SCV:CADE-2019}. 

Furthermore, we fix the problem-agnostic strategy parameters of the chosen \gls{atp}.
The parameters may specify for example a literal comparison mode, a saturation algorithm
\todo[author=Filip]{Are these examples or their terminology too specific for Vampire? Can we expect the reader to understand them?}
and a time limit.
We specifically assume that a finite time limit is used
because some proof searches may take too long for practical use\cite{?}
and we need to handle such searches gracefully.
% Note that an ATP that is complete is guaranteed to halt on a solvable problem.
% However, the solving time may vary greatly across the precedences.

\todo[inline,author=Filip]{Consider: Mention that we need to call the configured ATP to clausify the problem so that we know all the symbols including Tseitin and Skolem.}

For the sake of simplicity,
we will describe a system that only proposes predicate precedences.
\todo[inline,author=Filip]{Discuss more.
Possible generalizations to combination of predicate and function precedences:

- Learn predicate precedence in the context of frequency heuristic for function precedences. (current experiment)

- Learn predicate precedence in the context of random function precedences.

- Iterate: Learn predicate precedence in the context of function precedences from previous training epoch.

- Train predicate and function preference regressor simultaneously with a shared underlying GNN.}

\subsection{Main goals}

We strive to create a system that satisfies the following properties:

\begin{itemize}
	\item When presented with an arbitrary \gls{fol} problem,
	the system proposes a predicate precedence for this problem
	that maximizes the expected chance of the problem being solved
	within the allocated time.
	
	\todo[inline,author=Martin]{Maybe simply minimize the expected (abstract) solving time (i.e. measured in the number of iterations of the main loop!).}
	
	\item The system is trained on a collection of executions of the chosen prover
	on a training set of \gls{fol} problems
	with uniformly random predicate precedences.
	
	\item The architecture is general enough to be able to learn
	all the standard precedence heuristics implemented in Vampire.\cite{?}
	\todo[author=Filip]{Describe in more detail.}
\end{itemize}

\todo[inline,author=Filip]{Should we mention the following side goal? "Make it possible to backpropagate gradient to the input features for future GNN training."}

\subsection{Valuation of precedences}
\label{sec:precedence-valuation}

Based on the assumption that a short proof search is more likely to succeed in a limited time\cite{?},
we train the system to prefer precedences that lead to a short proof search.
This allows us to use easy problems for training, facilitating the collection of training data.

We define the base loss
\todo[author=Martin]{The term "loss" bears unnecessary ML connotations so this may be confusing.}
\todo[author=Filip]{Alternatives: cost, penalty, "value", "objective value"}
value of precedence \(\pi\) on a given problem
according to the outcome of the proof search configured to use this precedence:

\begin{itemize}
	\item If the proof search terminates within the allocated time,
	\(\base_loss(\pi)\) is the number of iterations of the saturation loop
	started during the proof search.
	\item If the proof search times out, \(\base_loss(\pi)\) is the maximum number
	of saturation loop iterations encountered in successful proof searches on this problem.
	\todo[author=Martin,inline]{Not even times 2?}
\end{itemize}

We further transform the loss values by the following operations:

\begin{enumerate}
	\item Log-scale: Multiplying the number of saturation iterations by a constant factor
	should have the same impact on the effective loss value
	irrespective of the problem and its particular distribution of saturation loop iteration counts.
	\item Standardization\cite{?}: For each problem,
	we apply an affine transformation so that the resulting loss values
	have the mean 0 and standard deviation 1.
	This ensures that the values are comparable across problems.
\end{enumerate}

Let \(\loss(\pi)\) denote the resulting loss value of permutation \(\pi\)
after scaling and standardization.

\subsection{Reduction to preference learning}

Let \(p \neq q\) be two predicates in a given \gls{problem}.
Each precedence \(\pi\) orders the predicates in some order --
either \(\inv{\pi}(p) < \inv{\pi}(q)\) or \(\inv{\pi}(p) > \inv{\pi}(q)\).
Ordering of some pairs of symbols can have a great impact on the speed of the proof search.
For example, prioritizing inferences on clauses with predicate symbols
introduced in Tseitin transformation
may lead to an exponential expansion of the affected clauses.

Let the pairwise preference
\todo[author=Filip]{Is it ok to use the name "preference" for a function that is to be minimized, thus actually a loss or a cost? I adopted it from LtOT terminology. Alternative: pairwise cost.}
function \(\pref : \Sigma_P \times \Sigma_P \rightarrow \re\)
\todo[author=Filip]{Explain the symbols.}
assign a preference value to each pair of predicate symbols:
a high value of \(\pref(p, q)\) corresponds to a long expected proof search time
if a precedence that orders \(p\) before \(q\) is used.
Furthermore, let the absolute value of \(\pref(p, q)\)
correspond to the expected magnitude of impact of the mutual order of \(p\) and \(q\).
Namely, \(\pref(p, q) = 0\) means that the mutual order of \(p\) and \(q\)
has no impact on the length of the proof search.

We proceed to relax the general task of finding a good precedence
to the task of finding a good pairwise preference function.
Once we have such function,
we will be interested in finding a precedence \(\pi\) that minimizes the cumulative preference value:

\begin{align*}
\loss_{proxy}(\pi) = \sum_{p, q: \inv{\pi}(p) < \inv{\pi}(q)} \pref(p, q)
\end{align*}
\todo[author=Filip]{Shall we call it "surrogate loss"? Our proxy loss seems to be positively aligned with the conventional use of the term but typically "surrogate loss" is differentiable.}

While the problem of minimizing \(\loss_{proxy}(\pi)\) given an arbitrary \(\pref\) is NP-hard,
a greedy 2-approximation algorithm exists.\cite{Cohen2011}

Note that such preference function may be trained by conventional machine learning techniques.

One possibility is to encode a precedence as an \gls{order-matrix}.

\subsection{Preference learning as supervised machine learning}

In order to cast the problem of finding an appropriate \(\pref\) function
as a supervised machine learning task,
we need to be able to represent each pair of predicate symbols by a feature vector
and to know preference values for pairs of symbols in the training set.

\subsubsection{Target preference values}

For each problem in the training set, we construct a preference matrix that contains a preference
value estimate for each pair of symbols in the problem.
We populate the matrix by the weights of a linear model trained on the following data:

\begin{itemize}
	\item Input: \Gls{order-matrix} of a precedence \(\pi\)
	\todo[author=Filip]{Explain in more detail what order matrix is.}
	\item Target: \(\loss(\pi)\) --
	a standardized result of an \gls{atp} run on \(\pi\) as defined in \autoref{sec:precedence-valuation}
\end{itemize}

This way we ensure that the preference matrix has a high value for a symbol pair \(l, r\)
if the precedences that order \(l\) before \(r\) have a high expected loss.

We use a lasso regression \cite{?} to train the model.
Advantages of using Lasso as opposed to standard linear regression\cite{?}:

\begin{itemize}
	\item Lasso implements regularization so it generalizes to unseen data better.
	\item Lasso prefers zero-valued weights so it is more likely to declare that the mutual order of a pair of symbols does not matter.
	\todo[author=Filip]{I think we should use RidgeCV or ElasticNetCV instead because they minimize L2 norm, while lasso only minimizes L1 norm.}
\end{itemize}

To avoid overfitting on the training precedence set,
we use cross-validation as implemented in sklearn.linear\_model.LassoCV \cite{?}
to set the regularization parameter.
Note that each problem may use a different value of the regularization parameter.

\subsubsection{Symbol pair embedding}

We represent each predicate symbol by a feature vector that consists of the following features:

\begin{itemize}
	\item Arity
	\item Usage count
	\item Unit usage count
	\item In goal
	\item In unit
\end{itemize}\todo[author=Filip]{Explain the meaning of each of these features.}

This choice is motivated by the fact that the values of all of these symbol properties
are readily available in the \gls{atp} Vampire
and that they suffice as a basis for all of the common symbol precedence heuristics.
\todo[author=Filip]{Claify more.}

We represent a pair of symbols \(l, r\) by the concatenation of their feature vectors.
\todo[inline,author=Filip]{Shall we remove problem embedding from the experiment for simplicity?}

\subsection{Sample weighting}

\todo[inline,author=Filip]{Finish.}

\subsection{Filip's notes}

Let \(\pi\) be a predicate precedence on a given \gls{fol} problem.
Let \(\loss(\pi)\) be a real number that corresponds to the performance of the chosen \gls{atp}
on the given \gls{fol} problem when using the predicate precedence \(\pi\).

Let the \gls{atp} Prover run on problem Problem with a time limit of 10 seconds.


For example, \(\loss(\pi)\) may be defined as the number of saturation loop iterations in case the prover

We strive to design and train a system that, when presented with any \gls{fol} problem,
proposes a predicate precedence for this problem with low expected \(loss\).
We want to train this system on a collection of executions of an \gls{atp}\footnote{We use the \gls{atp} Vampire in out experiments.} with random precedences on a training set of problems.

We break the task of generating a good precedence down to two stages:
\todo[author=Filip]{Why do we do that? \citet{Cohen2011} assumes that the pairwise preference is the input.}

\begin{enumerate}
	\item Estimate a pairwise loss function \(\loss_2\).
	\item Generate a permutation that maximizes the cumulative preference value.
\end{enumerate}

Notation:

\(\pi(i)\) is the \(i\)-th symbol under precedence \(\pi\).

\(\inv{\pi}(P)\) is the position of symbol \(P\) in precedence \(\pi\).

We work under the assumption that the overall performance of precedence \(\pi\) decomposes into a sum of contributions of ordered pairs of symbols:

\begin{align*}
\exists \loss_2 : \predicates \times \predicates \rightarrow \re . \loss(\pi) = \sum_{P, Q: \inv{\pi}(P) < \inv{\pi}(Q)} \loss_2(P, Q)
\end{align*}

Working under this assumption allows us to use \(\loss_2\) as a proxy for minimizing \(\loss\).
Note that each of the precedence heuristics implemented in Vampire can be expressed as minimizers of certain \(\loss_2\):

...



\section{Architecture}

\subsection{Prediction}

For a given problem, symbol precedence prediction consists of two steps:

\begin{enumerate}
	\item Preference matrix estimation
	\item Precedence construction from preference matrix
\end{enumerate}

\subsubsection{Preference matrix estimation}

Given a problem, we compute an embedding for each pair of symbols.
An embedding of a pair of symbols is a concatenation of the embeddings of the two symbols.
The embedding of a symbol consists of the following features:

\begin{itemize}
	\item Arity
	\item Usage count
	\item Unit usage count
	\item In goal
	\item In unit
	\item Skolem
\end{itemize}

The preference value regressor predicts a preference value for each symbol pair embedding.
We poll the preference value regressor for each pair of symbols of the input problem,
storing the preference values in a preference matrix.

\subsubsection{Precedence construction}

Given a preference matrix, we construct a symbol ordering
that approximately maximizes cumulative preference
using a greedy algorithm presented in LtOT.

\subsection{Training}

The training of preference value predictor consists of two stages:

\begin{enumerate}
	\item Problem-wise target preference matrix estimation
	\item Preference value regressor fitting
\end{enumerate}

\subsubsection{Problem-wise target preference matrix estimation}

For each problem,
we train a linear predictor
that predicts target score from \glspl{order-matrix}.
The coefficients of the trained predictor are the target preference values of the symbol pairs for this problem.

\subsubsection{Preference value regressor fitting}

As outlined in section ...,
the preference value regressor estimates a preference value for each symbol pair embedding.
It can be trained using any 

\section{Evaluation}
\label{sec:evaluation}

\section{Conclusion}

\glsaddall
\printglossaries

\bibliographystyle{plainnat}
\bibliography{main}

\end{document}
