\input{preamble}

\title{Learning Precedences from Simple Symbol Features\thanks{Supported by the ERC Consolidator grant AI4REASON no. 649043 under the EU-H2020 programme and the Czech Science Foundataion project 20-06390Y.}}
\titlerunning{Learning Precedences from Elementary Symbol Features}
\author{Filip B\'{a}rtek \and Martin Suda}
\authorrunning{B\'{a}rtek, Suda}
\institute{Czech Technical University in Prague, Czech Republic}

\begin{document}

\maketitle

\begin{abstract}
A simplification ordering, typically specified by a symbol precedence,
is one of the key parameters of the superposition calculus, contributing
to shaping the search space navigated by a saturation-based \acrlong{atp}.
Thus the choice of a precedence can have a great impact on the prover's performance.
In this work, we design a system for proposing favourable predicate symbol precedences.
The system relies on machine learning to extract the information from
past runs of a theorem prover over a set of problems and random precedences.
Moreover, it uses a small set of simple human-engineered symbol features as the sole
basis for discriminating the symbols. This allows for a direct comparison
with precedence construction heuristics designed by prover developers.
\todo[author=Martin]{Let's add this when we have the results finalized:
Training a linear model converges to ordering the symbols by the number of their occurrences.}
\end{abstract}

\section{Introduction}

Modern saturation-based Automated Theorem Provers (ATPs) such as E \cite{SCV:CADE-2019} and Vampire \cite{Kovacs2013}
use the superposition calculus \cite{Nieuwenhuis2001} as their underlying inference system.
Superposition is built around the paramodulation inference \cite{Robinson1983} crucially
constrained by simplification ordering on terms and literals, which is supplied as a parameter of the calculus.
Each of the two classes of simplification orderings used in practice,
i.e., the Knuth-Bendix Ordering (KBO) \cite{Knuth1983}
and the Lexicographic Path Ordering (LPO) \cite{Kamin1980},
are mainly determined by a pair of \emph{symbol precedences}, permutations of the sets of predicate and function symbols,
respectively.\footnote{
KBO is further parameterized by symbol weights, but our reference implementation in Vampire~\cite{Kovacs2013} 
uses for efficiency reasons only weights equal to one \cite{DBLP:conf/cade/KovacsMV11} and so we do not consider this parameter here.}

While the superposition calculus is known \cite{DBLP:journals/logcom/BachmairG94} to be refutationally complete for any simplification ordering, the choice of the precedences may have a significant impact on how long it takes to solve a given problem.
In a well-known example, prioritizing in the precedence the predicates introduced during the Tseitin transformation of an input formula \cite{Tseitin1983} exposes the corresponding literals to resolution inference during early stages of the proof search,
with the effect of essentially undoing the transformation and thus threatening with an exponential blow-up
the transformation is designed to prevent \cite{Reger2016}.
%
ATPs typically offer a few heuristic schemes for generating the symbol precedences.
For example, the successful \texttt{invfreq} scheme in E \cite{E-manual} orders the symbols by the number of occurrences in the input problem,
prioritizing symbols that occur the least often for early inferences.
Experiments with random precedences have shown that the existing schemes often fail to come close to the optimum precedence \cite{RegerSuda2017}, revealing there is a large potential for further improvements.

In this work, we design a system that, when presented with a First-Order Logic (FOL) problem,
proposes a symbol precedence that will likely lead to solving the problem quickly.
The system relies on the techniques of supervised machine learning and extracts
such theorem-proving knowledge from successful (and unsuccessful) runs of 
the Vampire theorem prover~\cite{Kovacs2013} when run over a variety of FOL problems equipped
with randomly sampled symbol precedences. 
We assume that by learning to solve already solvable problems quickly,
the acquired knowledge will generalize and help solving problems previously out of reach.
% This general assumption is shared with other projects for automatically learning theorem
% proving strategies from previous experience, such as the MaLeS system \cite{DBLP:journals/jar/KuhlweinU15}.
As a first step in a more ambitions project,
we focus here on representing the symbols in a problem by a fixed set of simple human-engineered features
(such as the number the occurrences used by \texttt{invfreq} scheme mentioned above)\footnote{Automatic
feature extraction using neural-networks is planned for future work.}
and, to simplify the experimental setup, we restrict our attention to learning precedences for predicate symbols only.\footnote{
Our theoretical considerations, however, apply equally to learning function symbol precedences.}

Learning to predict good precedences poses several interesting challenges that we address in this work.
First, it is not immediately clear how to characterise a precedence, a permutation of a finite set of symbols,
by a real-valued feature vector to serve as an input for a learning algorithm. 
Additionally, to be able to generalise across problems
we need to do it in a way which does not presuppose a fixed signature size. 
There is also a complication, when sampling different problems,
that some problems may be easy to solve for almost every precedence and others hard.
In theorem proving, running times typically vary considerably.
Finally, even with a regression model ready to predict the prover's performance 
under a particular precedence $\pi$, we still need solve the task of finding 
the ideally optimal precedence $\pi^*$ according to this model.

% Final paragraph, with forward reference, explaines how we tackle the challenges and where it is explained
% 1) preference values
% 2) normalization
% 3) learning to order things

% ze n! je super large -> almost infinite source of data (for non-trivial n)

% ----

% Zastrc nekam dozadu na pozdeji

% - we use abstract time as the basic measure
% (why not actual time to solve a problem? Unstable, abstract time is machine independent and still correlates well)

% - zmin konkretni stratgie, kterou pouzivame a variujeme v ni pouze predikatovou precendenci
% (vcetne toho, ze funknci precedenci fixujeme na frequency)

\newpage

\section{Preliminaries / Notation / Background}

% We assume the reader is familiar with this and that

% Regression algorithms; (Maybe not here yet: we do it in Python - scikitlearn, numpy, \ldots)

\newpage

\section{Introduction}

The most successful \gls{fol} \glspl{atp} are based on superposition calculus,
which is parameterized by simplification term ordering.
Each of the two most commonly used simplification orderings, \gls{kbo} and \gls{lpo},
is in turn parameterized by a pair of symbol precedences:
predicate precedence and function precedence.
Each of these precedences is a permutation of the respective symbols of the problem under consideration.

In this text we limit ourselves to discussion of predicate symbol precedences for the sake of simplicity.
We fix function precedences to use the frequency heuristic.

Given a problem, we look for a predicate \gls{precedence} that leads to a successful and quick proof search.

\Gls{preference-value} of an ordered pair of symbols \((P_0, P_1)\) expresses a penalty associated with ordering the symbol \(P_0\) before the symbol \(P_1\).
Positive value means that ordering \(P_0\) before \(P_1\) is associated with low probability of success.
Negative value means that ordering \(P_0\) before \(P_1\) is associated with high probability of success.
Value close to zero means that the order of symbols \(P_0\) and \(P_1\) has no effect on the probability of success.

\Gls{preference-matrix} is a square matrix populated with preference values of all the pairs of symbols.

For a given symbol precedence,
\gls{order-matrix} \(C\) is a boolean square matrix of size \(n \times n\) where \(n\) is the number of symbols.
\(C_{i, j}\) is true if and only if symbol \(P_i\) precedes symbol \(P_j\) in the precedence.

\subsection{Notation}

If \(\pi\) is a symbol precedence, that is a permutation of symbols:

\begin{itemize}
	\item \(\pi(i)\) is the \(i\)-th symbol in precedence \(\pi\).
	\item \(\inv{\pi}(p)\) is the position of symbol \(p\) in precedence \(\pi\).
	\todo[author=Filip]{Should we specify that we use 1-based indexing? Should we use 0-based indexing instead?}
\end{itemize}

For example, if \(\pi = (q, p, r)\), then \(\pi(2) = p\) and \(\inv{\pi}(p) = 2\).

For a given problem \(\predicates\) is the set of all predicate symbols in the problem
and \(\functions\) is the set of all function symbols in the problem.

\section{Architecture}

\subsection{Basic assumptions}

For the discussion that follows in this section,
we assume a fixed \gls{fol} \gls{atp} that uses superposition calculus parameterized by symbol precedence.
\todo[author=Filip]{Consider different approach: "For the discussion that follows, we assume that Vampire is used. We keep the discussion general enough to accommodate any precedence-parameterized ATP." and use "Vampire" instead of "ATP" in sections that follow.}
While the practical experiments described in \autoref{sec:evaluation} use the \gls{atp} \gls{vampire} \cite{Kovacs2013},
\todo[author=Filip]{Remove if we end up omitting practical experiments.}
the model architecture does not assume a particular \gls{atp}
and is compatible with any superposition-based \gls{atp} such as \gls{vampire} or E \cite{SCV:CADE-2019}.

Furthermore, we fix the problem-agnostic strategy parameters of the chosen \gls{atp}.
The parameters may specify for example a literal comparison mode, a saturation algorithm
\todo[author=Filip]{Are these examples or their terminology too specific for Vampire? Can we expect the reader to understand them?}
and a time limit.
We specifically assume that a finite time limit is used
because some proof searches may take too long for practical use\cite{?}
and we need to handle such searches gracefully.
% Note that an ATP that is complete is guaranteed to halt on a solvable problem.
% However, the solving time may vary greatly across the precedences.

\todo[inline,author=Filip]{Consider: Mention that we need to call the configured ATP to clausify the problem so that we know all the symbols including Tseitin and Skolem.}

For the sake of simplicity,
we will describe a system that only proposes predicate precedences, ignoring function precedences.
\todo[inline,author=Filip]{Discuss more.
Possible generalizations to combination of predicate and function precedences:

- Learn predicate precedence in the context of frequency heuristic for function precedences. (current experiment)

- Learn predicate precedence in the context of random function precedences.

- Iterate: Learn predicate precedence in the context of function precedences from previous training epoch.

- Train predicate and function preference regressor simultaneously with a shared underlying GNN.}

\subsection{Main goals}

We strive to create a system that satisfies the following properties:

\begin{itemize}
	\item When presented with an arbitrary \gls{fol} problem,
	the system proposes a predicate precedence for this problem
	that maximizes the expected chance of the problem being solved
	within the allocated time.
	\todo[author=Filip]{What distribution of problems do we optimize for?}
	
	\todo[inline,author=Martin]{Maybe simply minimize the expected (abstract) solving time (i.e. measured in the number of iterations of the main loop!).}
	
	\item The system is trained on a collection of executions of the chosen prover
	on a training set of \gls{fol} problems
	with uniformly random predicate precedences.
	
	\item The architecture is general enough to be able to learn
	all the standard precedence heuristics implemented in Vampire.\cite{?}
	\todo[author=Filip]{Describe in more detail.}
\end{itemize}

\todo[inline,author=Filip]{Should we mention the following side goal? "Make it possible to backpropagate gradient to the input features for future GNN training."}

\subsection{Valuation of precedences}
\label{sec:precedence-valuation}

Based on the assumption that a short proof search is more likely to succeed in a limited time\cite{?},
we train the system to prefer precedences that lead to a short proof search.
This allows us to use easy problems for training, facilitating the collection of training data.

We define the base cost
value \(\CostBase(P, \pi_P)\) of precedence \(\pi_P\) on problem \(P\)
according to the outcome of the proof search configured to use this precedence:

\begin{itemize}
	\item If the proof search successfully terminates within the allocated time,
	\(\CostBase(\pi_P)\) is the number of iterations of the saturation loop
	started during the proof search.
	\item If the proof search times out, \(\CostBase(\pi_P)\) is the maximum number
	of saturation loop iterations encountered in successful proof searches on this problem.
	\todo[author=Martin,inline]{Not even times 2?}
\end{itemize}

We further transform the cost values by the following operations:

\begin{enumerate}
	\item Logarithmic scaling: Multiplying the number of saturation iterations by a constant factor
	should have the same impact on the effective cost value
	irrespective of the problem and its particular distribution of saturation loop iteration counts.
	\todo[author=Filip]{We have observed that the order of number of iterations differs across problems -- some problems run tens of iterations in 10 seconds, while other problems run thousands of iterations. Shall we mention this?}
	\item Standardization\cite{?}: For each problem,
	we apply an affine transformation so that the resulting cost values
	have the mean 0 and standard deviation 1.
	This ensures that the values are comparable across problems.
\end{enumerate}

Let \(\CostStd(\pi_P)\) denote the resulting cost value of permutation \(\pi_P\)
after scaling and standardization.

\subsection{Reduction to preference learning}

Let \(p \neq q\) be two predicates in a given \gls{problem} \(P\).
Each precedence \(\pi_P\) orders the predicates in some order --
either \(\inv{\pi_P}(p) < \inv{\pi_P}(q)\) or \(\inv{\pi_P}(p) > \inv{\pi_P}(q)\).
Ordering of some pairs of symbols can have a great impact on the speed of the proof search.
For example, prioritizing inferences on clauses with predicate symbols
introduced in Tseitin transformation
may lead to an exponential expansion of the affected clauses.

Let the pairwise preference
\todo[author=Filip]{Is it ok to use the name "preference" for a function that is to be minimized, thus actually a cost? I adopted it from LtOT terminology. Alternative: pairwise cost.}
function \(\pref : \predicates \times \predicates \rightarrow \re\)
\todo[author=Filip]{Explain the symbols.}
assign a preference value to each pair of predicate symbols:
a high value of \(\pref(p, q)\) corresponds to a long expected proof search time
if a precedence that orders \(p\) before \(q\) is used.
Furthermore, let the absolute value of \(\pref(p, q)\)
correspond to the expected magnitude of impact of the mutual order of \(p\) and \(q\).
Namely, \(\pref(p, q) = 0\) means that the mutual order of \(p\) and \(q\)
has no impact on the length of the proof search.

We proceed to relax the general task of finding a good precedence
to the task of finding a good pairwise preference function.
Once we have such function,
we will be interested in finding a precedence \(\pi_P\) that minimizes the cumulative preference value:

\begin{align*}
\CostProxy(\pi_P) = \sum_{p, q: \inv{\pi_P}(p) < \inv{\pi_P}(q)} \pref(p, q)
\end{align*}
\todo[author=Filip]{Shall we call it "surrogate loss"? Our proxy cost seems to be positively aligned with the conventional use of the term but typically "surrogate loss" is differentiable.}

While the problem of minimizing \(\CostProxy(\pi_P)\) given an arbitrary \(\pref\) is NP-hard,
a greedy 2-approximation algorithm exists.\cite{Cohen2011}
\todo[author=Filip]{Discuss: Is the algorithm acceptable despite the fact that it does not guarantee to find the optimum?}

Note that each of the precedence heuristics implemented in Vampire minimizes \(\CostProxy\)
for a particular \(\pref\).
\todo[author=Filip]{Discuss in more detail.}
\todo[inline,author=Filip]{Do we really cover all Vampire heuristics? How about \texttt{occurrence}, \texttt{scramble}, \texttt{weighted\_frequency}, \texttt{reverse\_weighted\_frequency}? What about \texttt{--symbol\_precedence\_boost}?}

\subsection{Preference learning as supervised machine learning}

In order to cast the problem of finding an appropriate \(\pref\) function
as a supervised machine learning task,
and to know preference values for pairs of symbols in the training set.

\subsubsection{Target preference values}

For each problem in the training set, we construct a preference matrix that contains a preference
value estimate for each pair of symbols in the problem.
\todo[inline,author=Filip]{Why do we do this? Why don't we just take \(\CostStd\) as the target value? My intuition is that this way we get less variance in the target values. Our approach also possibly enables (or improves) sample weighting by absolute value of \(\pref\). I think we originally chose to use lasso because on a fixed problem lasso outperforms "MeanRegression" -- lasso generalizes better. But we could alternatively rely on regularization in the outer regression! We would probably need more samples to train the outer regression, but the model simplicity and saving time to train the inner regressors may be worth it.}
We populate the matrix by the weights of a linear model trained on data
collected from a number of \gls{atp} runs on random precedences.
Each training sample has the following structure:

\begin{itemize}
	\item Input: Flattened \gls{order-matrix} of a precedence \(\pi_P\)
	\todo[author=Filip]{Explain in more detail what order matrix is.}
	\item Target: \(\CostStd(\pi_P)\) --
	a standardized result of an \gls{atp} run on \(\pi_P\) as defined in \autoref{sec:precedence-valuation}
\end{itemize}

This way we ensure that the preference matrix has a high value for a symbol pair \(l, r\)
if the precedences that order \(l\) before \(r\) have a high expected cost.

We use lasso regression \cite{?} to train the model.
Advantages of using lasso as opposed to standard linear regression\cite{?}:

\begin{itemize}
	\item Lasso implements regularization so it generalizes to unseen data better.
	\item Lasso prefers zero-valued weights so it is more likely to declare that the mutual order of a pair of symbols does not matter.
	\todo[author=Filip]{I think we should use RidgeCV or ElasticNetCV instead because they minimize L2 norm, while lasso only minimizes L1 norm.}
\end{itemize}

To ensure good generalization,
we use cross-validation as implemented in sklearn.linear\_model.LassoCV \cite{?}
to set the regularization parameter.
Note that each problem may use a different value of the regularization parameter.
\todo[inline,author=Filip]{Don't we need to use the same value of regularization parameter in order for the preference matrix values to be comparable across problems?}

\subsubsection{Symbol pair embedding}

We represent each predicate symbol by a feature vector that consists of the following features:

\begin{itemize}
	\item Arity
	\item Usage count
	\item Unit usage count
	\item In goal
	\item In unit
\end{itemize}\todo[author=Filip]{Explain the meaning of each of these features.}

This choice is motivated by the fact that the values of all of these symbol properties
are readily available in the \gls{atp} Vampire
and that they suffice as a basis for all of the common symbol precedence heuristics.
\todo[author=Filip]{Claify more.}

We represent a pair of symbols \(l, r\) by the concatenation of their feature vectors.
\todo[inline,author=Filip]{Shall we remove problem embedding from the experiment for simplicity? I have omitted problem embedding in this text.}

\subsection{Sample weighting}

\todo[inline,author=Filip]{My choice to use sample weighting was based on measurements. If we exclude measurements, we should probably exclude sample weighting as well unless we come up with a good theoretical justification.}

\section{Evaluation}
\label{sec:evaluation}

\todo[inline]{Finish. Shall we describe experimental results? Or how we plan to evaluate the architecture? Or how we plan to tweak hyperparameters?}

\section{Conclusion}

\todo[inline]{Finish.}

\glsaddall
\printglossaries

\bibliographystyle{plainnat}
\bibliography{main}

\end{document}
