\input{preamble}

\title{Learning Precedences from Simple Symbol Features\thanks{Supported by the ERC Consolidator grant AI4REASON no. 649043 under the EU-H2020 programme and the Czech Science Foundataion project 20-06390Y.}}
\titlerunning{Learning Precedences from Elementary Symbol Features}
\author{Filip B\'{a}rtek \and Martin Suda}
\authorrunning{B\'{a}rtek, Suda}
\institute{Czech Technical University in Prague, Czech Republic}

\begin{document}

\maketitle

\begin{abstract}
A simplification ordering, typically specified by a symbol precedence,
is one of the key parameters of the superposition calculus, contributing
to shaping the search space navigated by a saturation-based \acrlong{atp}.
Thus the choice of a precedence can have a great impact on the prover's performance.
In this work, we design a system for proposing symbol precedences
that should lead to solving a problem quickly.
The system relies on machine learning to extract this information from
past successful and unsuccessful runs of a theorem prover over a set of problems and random precedences.
Moreover, it uses a small set of simple human-engineered symbol features as the sole
basis for discriminating the symbols. This allows for a direct comparison
with precedence generation schemes designed by prover developers.
\todo[author=Martin]{Let's add this when we have the results finalized:
Training a linear model converges to ordering the symbols by the number of their occurrences.}
\end{abstract}

\section{Introduction}

Modern saturation-based \glspl{atp} such as E \cite{SCV:CADE-2019} and \gls{vampire} \cite{Kovacs2013}
use the superposition calculus \cite{Nieuwenhuis2001} as their underlying inference system.
Superposition is built around the paramodulation inference \cite{Robinson1983} crucially
constrained by simplification ordering on terms and literals, which is supplied as a parameter of the calculus.
Both of the two main classes of simplification orderings used in practice,
i.e., the \acrlong{kbo} \cite{Knuth1983}
and the \acrlong{lpo} \cite{Kamin1980},
are mainly determined by a %pair of 
\emph{symbol precedence}, a (partial) ordering on the signature symbols.\footnote{
KBO is further parameterized by symbol weights, but our reference implementation in Vampire~\cite{Kovacs2013} 
uses for efficiency reasons only weights equal to one \cite{DBLP:conf/cade/KovacsMV11} and so we do not consider this parameter here.}

While the superposition calculus is known \cite{DBLP:journals/logcom/BachmairG94} to be refutationally complete for any simplification ordering, the choice of the precedence may have a significant impact on how long it takes to solve a given problem.
In a well-known example, prioritizing in the precedence the predicates introduced during the Tseitin transformation of an input formula \cite{Tseitin1983} exposes the corresponding literals to resolution inference during early stages of the proof search,
with the effect of essentially undoing the transformation and thus threatening with an exponential blow-up
the transformation is designed to prevent \cite{Reger2016}.
%
ATPs typically offer a few heuristic schemes for generating the symbol precedences.
For example, the successful \texttt{invfreq} scheme in E \cite{E-manual} orders the symbols by the number of occurrences in the input problem,
prioritizing symbols that occur the least often for early inferences.
Experiments with random precedences have shown that the existing schemes often fail to come close to the optimum precedence \cite{RegerSuda2017}, revealing there is a large potential for further improvements.

In this work, we design a system that, when presented with a First-Order Logic (FOL) problem,
proposes a symbol precedence that will likely lead to solving the problem quickly.
The system relies on the techniques of supervised machine learning and extracts
such theorem-proving knowledge from successful (and unsuccessful) runs of 
the Vampire theorem prover~\cite{Kovacs2013} when run over a variety of FOL problems equipped
with randomly sampled symbol precedences. 
We assume that by learning to solve already solvable problems quickly,
the acquired knowledge will generalize and help solving problems previously out of reach.
% This general assumption is shared with other projects for automatically learning theorem
% proving strategies from previous experience, such as the MaLeS system \cite{DBLP:journals/jar/KuhlweinU15}.
As a first step in a more ambitions project,
we focus here on representing the symbols in a problem by a fixed set of simple human-engineered features
(such as the number the occurrences used by \texttt{invfreq} scheme mentioned above)\footnote{Automatic
feature extraction using neural-networks is planned for future work.}
and, to simplify the experimental setup, we restrict our attention to learning precedences for predicate symbols only.\footnote{
Our theoretical considerations, however, apply equally to learning function symbol precedences.}

Learning to predict good precedences poses several interesting challenges that we address in this work.
First, it is not immediately clear how to characterise a precedence, a permutation of a finite set of symbols,
by a real-valued feature vector to serve as an input for a learning algorithm. 
Additionally, to be able to generalise across problems
we need to do it in a way which does not presuppose a fixed signature size. 
There is also a complication, when sampling different problems,
that some problems may be easy to solve for almost every precedence and others hard.
In theorem proving, running times typically vary considerably.
Finally, even with a regression model ready to predict the prover's performance 
under a particular precedence $\pi$, we still need solve the task of finding 
the ideally optimal precedence $\pi^*$ according to this model.

% Final paragraph, with forward reference, explaines how we tackle the challenges and where it is explained
% 1) preference values
% 2) normalization
% 3) learning to order things

\newpage

\section{Preliminaries}

\subsection{Terminology}

We assume that the reader is familiar with basic concepts used in \gls{fol} theorem proving
such as \gls{fol} problem, problem signature, predicate symbol, function symbol, clause and \gls{cnf}.
Furthermore we assume familiarity with basics of the inner workings of saturation-based \glspl{atp},
including clausification and saturation loop.

% Regression algorithms; (Maybe not here yet: we do it in Python - scikitlearn, numpy, \ldots)

\paragraph{Problem}
A \emph{(first-order) problem} is a pair \(P = (\Sigma, \clauses)\),
where \(\Sigma = (s_1, s_2, \ldots, s_n)\) is a list of (predicate and function) symbols called the \emph{signature},
and \(\clauses\) is a set of first-order
clauses built over the symbols of \(\Sigma\).

The problem is either given directly by the user or 
could be the result of clausifying a general \gls{fol} formula \(\varphi\),
in which case we know which of the symbols were introduced during the clausification
(namely during Tseitin transformation and skolemization; see e.g. \citet{DBLP:books/el/RV01/NonnengartW01}).

\paragraph{Precedence}
Given a problem \(P = (\Sigma, \clauses)\) with \(\Sigma = (s_1, s_2, \ldots, s_n)\),
a precedence \(\pi_P\) is a permutation, i.e.~a bijective mapping, of the set of indices \(\{1,\ldots,n\}\).
A precedence \(\pi_P\) \emph{determines} a (total) ordering on \(\Sigma\) as follows:
\(s_{\pi_P(1)} < s_{\pi_P(2)} < \ldots < s_{\pi_P(n)}.\)
\todo[author=Filip]{Why the emphasis on "determines"?}

\paragraph{Simplification Orderings} are orderings on terms used to parametrise the superposition calculus \cite{Nieuwenhuis2001}
employed by modern saturation-based theorem provers. The two classes of simplification orderings mostly used in practice,
the \acrlongpl{kbo} \cite{Knuth1983} and the \acrlongpl{lpo} \cite{Kamin1980}, are both defined in terms 
of a user-supplied (possibly partial) ordering $<$ %(typically also called the precedence) 
on the given problem's signature \(\Sigma\).
In this work, we assume that a theorem prover uses a simplification ordering from one of these two classes
relying on the ordering on \(\Sigma\) determined by a precedence \(\pi_P\) to construct such a simplification ordering.

\paragraph{Performance measure} A saturation-based \gls{atp} \emph{solves} a problem \(P = (\Sigma,\clauses)\)
(under a particular fixed strategy and a determined symbol precedence \(\pi_P\))  by either
\begin{itemize}
\item
	deriving from \(\clauses\) a contradiction in the form of the empty clause,
	in which case \(P\) is shown \emph{unsatisfiable}, or
\item
	finitely saturating the set of clauses \(\clauses\) without deriving the contradiction,
	in which case \(P\) is shown \emph{satisfiable}.\footnote{We assume a \emph{refutationally complete} strategy.}	
\end{itemize}
In both cases, we take the number of iterations of the employed saturation algorithm (see, e.g., \citet{DBLP:journals/jsc/RiazanovV03} for an overview) as a measure of effort that the \gls{atp} took to solve the problem.
We will refer to this measure as the \emph{abstract solving time} and denote it \(\mathit{ast}(P,\pi_P)\).\footnote{
The advantage of using abstract solving time is that it does not depend on the hardware used for the computation.}

In practice, an \gls{atp} can also run out of resources, typically out of the allocated time.
In that case, the abstract solving time is \emph{undefined}: \(\mathit{ast}(P,\pi_P) = \bot\).

\newpage

\paragraph{\Gls{order-matrix}}
Given a permutation \(\pi\) of length \(n\),
the \gls{order-matrix} \(\OrderMatrix(\pi)\) is a binary matrix of size \(n \times n\)
defined in the following manner:

\begin{align*}
\OrderMatrix(\pi)_{i, j} = \indicator{\inv{\pi}(i) < \inv{\pi}(j)}
\end{align*}

We use \(\indicator{P}\) to denote the Iverson bracket \cite{Iverson1962} applied to proposition \(P\),
evaluating to 1 if \(P\) is true, and 0 otherwise.
% In \citet{Iverson1962}, the expression is called "relational statement".

Namely for a predicate precedence \(\pi_P\), \(O(\pi_P)_{i, j} = 1\) if
the precedence \(\pi_P\) orders predicate \(p_i\) before predicate \(p_j\),
and \(O(\pi_P)_{i, j} = 0\) otherwise.

\paragraph{Flattened matrix}
Given a matrix \(M\) of size \(n \times n\),
\(\flatten{M}\) is the vector of length \(n^2\) obtained by flattening \(M\):

\begin{align*}
\flatten{M}_{(i - 1) n + j} = M_{i, j}
\end{align*}
\todo[author=Filip]{Should we include universal quantification for i, j?}

\todo[inline,author=Martin]{What is linear regression? Define and cite.}
\todo[inline,author=Martin]{Define sufficient apparatus to be able to prove that if we use linear regression for the general preference prediction, than we can construct optimum precedence in linear time from the coefficients. Write down the proof.}

\subsection{Basic assumptions}

For the discussion that follows,
we assume a fixed \gls{fol} \gls{atp} that uses superposition calculus parameterized by symbol precedence.
\todo[author=Filip]{Consider different approach: "For the discussion that follows, we assume that Vampire is used. We keep the discussion general enough to accommodate any precedence-parameterized ATP." and use "Vampire" instead of "ATP" in sections that follow.}
While the practical experiments described in \autoref{sec:evaluation} use the \gls{atp} \gls{vampire} \cite{Kovacs2013},
\todo[author=Filip]{Remove if we end up omitting practical experiments.}
the model architecture does not assume a particular \gls{atp}
and is compatible with any superposition-based \gls{atp} such as \gls{vampire} or E \cite{SCV:CADE-2019}.

Furthermore, we fix the problem-agnostic strategy parameters of the chosen \gls{atp}.
The parameters may specify for example a literal comparison mode, a saturation algorithm
\todo[author=Filip]{Are these examples or their terminology too specific for Vampire? Can we expect the reader to understand them?}
and a time limit.
We specifically assume that a finite time limit is used
because some proof searches may take too long for practical use\cite{?}
and we need to handle such searches gracefully.
% Note that an ATP that is complete is guaranteed to halt on a solvable problem.
% However, the solving time may vary greatly across the precedences.

\todo[inline,author=Filip]{Consider: Mention that we need to call the configured ATP to clausify the problem so that we know all the symbols including Tseitin and Skolem.}

For the sake of simplicity,
we will describe a system that only proposes predicate precedences, ignoring function precedences.
\todo[inline,author=Filip]{Discuss more.
	Possible generalizations to combination of predicate and function precedences:
	
	- Learn predicate precedence in the context of frequency heuristic for function precedences. (current experiment)
	
	- Learn predicate precedence in the context of random function precedences.
	
	- Iterate: Learn predicate precedence in the context of function precedences from previous training epoch.
	
	- Train predicate and function preference regressor simultaneously with a shared underlying GNN.}

\newpage

\section{Introduction [by Filip]}
\todo[inline,author=Filip]{Join this section with the first Introduction section.}

The most successful \gls{fol} \glspl{atp} are based on superposition calculus,
which is parameterized by simplification term ordering.
Each of the two most commonly used simplification orderings, \gls{kbo} and \gls{lpo},
is in turn parameterized by a pair of symbol precedences:
predicate precedence and function precedence.
Each of these precedences is a permutation of the respective symbols of the problem under consideration.

In this text we limit ourselves to discussion of predicate symbol precedences for the sake of simplicity.
We fix function precedences to use the frequency heuristic.

Given a problem, we look for a predicate \gls{precedence} that leads to a successful and quick proof search.

\Gls{preference-value} of an ordered pair of symbols \((P_0, P_1)\) expresses a penalty associated with ordering the symbol \(P_0\) before the symbol \(P_1\).
Positive value means that ordering \(P_0\) before \(P_1\) is associated with low probability of success.
Negative value means that ordering \(P_0\) before \(P_1\) is associated with high probability of success.
Value close to zero means that the order of symbols \(P_0\) and \(P_1\) has no effect on the probability of success.

\Gls{preference-matrix} is a square matrix populated with preference values of all the pairs of symbols.

\newpage

\section{Architecture}
\label{sec:architecture}

The aim of this work is to design a system that learns to suggest good symbol precedences to an ATP 
from observations of the ATP's performance on a class $\mathcal{P}$ of problems with randomly sampled precedences. 
Given a problem \(P = (\Sigma,\clauses)\) with \(|\Sigma|=n\), we consider a precedence \(\pi_P\) good 
if it leads to a low \(\mathit{ast}(P,\pi_P)\) among the $n!$ possible precedences for \(P\).
% ze n! je super large -> almost infinite source of data (for non-trivial n)
Note that for problems with a signature with more than a few symbols, repeatedly running the prover 
with random precedences represents an effectively infinite source of training data.

Ideally, we would like to learn general theorem proving knowledge, not too dependent on $\mathcal{P}$,
which could be later explained and compared to precedence generation schemes manually designed 
by the prover developers. Let us quickly recall one such scheme, already mentioned in the introduction,
called \texttt{invfreq} in E \cite{SCV:CADE-2019}. The prover's manual \cite{E-manual} explains:
\begin{quote}
Sort symbols by frequency (frequently occurring symbols are smaller).
\end{quote}
What is common to basically all manually designed schemes, is that they pick a certain scalar property of symbols 
% information retrieval terminology
(here it is symbol the frequency, i.e.~the number of occurrences of the symbol in the given problem)
and obtain a precedence by \emph{sorting} the symbols using that property.


\newpage


% each problem has it's own signature, so the precedences is a problems specific beast and ...
% 









We might want our system to also learn a certain property of symbols and use sorting to generate and suggest a precedence. However, 




% computational complexity considerations




% Challenges to define the flow

% 1) - characterise a precedence, a permutation of a finite set of symbols, by a real-valued feature vector
% 2) - across problems we need to do it in a way which does not presuppose a fixed signature size

% learning pairwise preferences

% 3) - some problems may be easy to solve for almost every precedence and others hard.
% In theorem proving, running times typically vary considerably.

%) standardization (log scale & centering)

%4) - regression model ready to predict the prover's performance 
% under a particular precedence $\pi$, we still need solve the task of finding 
% the ideally optimal precedence $\pi^*$ according to this model.

% ---> learning to order things (greedy), 
% hillclimb - from greedy, from random (try many times)





% ----

% Zastrc nekam dozadu na pozdeji

% - we use abstract time as the basic measure
% (why not actual time to solve a problem? Unstable, abstract time is machine independent and still correlates well)

% - zmin konkretni stratgii, kterou pouzivame a variujeme v ni pouze predikatovou precendenci
% (vcetne toho, ze funkcni precedenci fixujeme na frequency)



\newpage

\subsection{Main goals}

We strive to create a system that satisfies the following properties:

\begin{itemize}
	\item When presented with an arbitrary \gls{fol} problem,
	the system proposes a predicate precedence for this problem
	that maximizes the expected chance of the problem being solved
	within the allocated time.
	\todo[author=Filip]{What distribution of problems do we optimize for?}
	
	\todo[inline,author=Martin]{Maybe simply minimize the expected (abstract) solving time (i.e. measured in the number of iterations of the main loop!).}
	
	\item The system is trained on a collection of executions of the chosen prover
	on a training set of \gls{fol} problems
	with uniformly random predicate precedences.
	
	\item The architecture is general enough to be able to learn
	all the standard precedence heuristics implemented in Vampire.\cite{?}
	\todo[author=Filip]{Describe in more detail.}
\end{itemize}

\todo[inline,author=Filip]{Should we mention the following side goal? "Make it possible to backpropagate gradient to the input features for future GNN training."}

\subsection{Valuation of precedences}
\label{sec:precedence-valuation}

Based on the assumption that a short proof search is more likely to succeed in a limited time\cite{?},
we train the system to prefer precedences that lead to a short proof search.
This allows us to use easy problems for training, facilitating the collection of training data.

We define the base cost
value \(\CostBase(P, \pi_P)\) of precedence \(\pi_P\) on problem \(P\)
according to the outcome of the proof search configured to use this precedence:

\begin{itemize}
	\item If the proof search successfully terminates within the allocated time,
	\(\CostBase(\pi_P)\) is the number of iterations of the saturation loop
	started during the proof search.
	\item If the proof search times out, \(\CostBase(\pi_P)\) is the maximum number
	of saturation loop iterations encountered in successful proof searches on this problem.
	\todo[author=Martin,inline]{Not even times 2?}
\end{itemize}

We further normalize the cost values by the following operations:

\begin{enumerate}
	\item Logarithmic scaling:
	For each solvable problem, running proof search with uniformly random predicate precedences
	reveals a distribution of numbers of saturation iterations.
	Examining these distributions for various problems suggests that they are usually
	approximately log-normal.
	To make further scaling by standardization reasonable,
	we first transform the base costs by considering their logarithms.
	\item Standardization\cite{?}:
	\todo[author=Filip]{We can use the more general term "normalization" instead. Our goal is to normalize the values and standardization is the means we choose.}
	For each problem,
	we apply an affine transformation so that the resulting cost values
	have the mean 0 and standard deviation 1.
	This ensures that the values are comparable across problems.
\end{enumerate}

Let \(\CostStd(\pi_P)\) denote the resulting cost value of permutation \(\pi_P\)
after scaling and standardization.

\subsection{Reduction to preference learning}

Let \(p \neq q\) be two predicates in a given \gls{problem} \(P\).
Each precedence \(\pi_P\) orders the predicates in some order --
either \(\inv{\pi_P}(p) < \inv{\pi_P}(q)\) or \(\inv{\pi_P}(p) > \inv{\pi_P}(q)\).
Ordering of some pairs of symbols can have a great impact on the speed of the proof search.
For example, prioritizing inferences on clauses with predicate symbols
introduced in Tseitin transformation
may lead to an exponential expansion of the affected clauses.

Let the pairwise preference
\todo[author=Filip]{Is it ok to use the name "preference" for a function that is to be minimized, thus actually a cost? I adopted it from LtOT terminology. Alternative: pairwise cost.}
function \(\pref : \predicates \times \predicates \rightarrow \re\)
\todo[author=Filip]{Explain the symbols.}
assign a preference value to each pair of predicate symbols:
a high value of \(\pref(p, q)\) corresponds to a long expected proof search time
if a precedence that orders \(p\) before \(q\) is used.
Furthermore, let the absolute value of \(\pref(p, q)\)
correspond to the expected magnitude of impact of the mutual order of \(p\) and \(q\).
Namely, \(\pref(p, q) = 0\) means that the mutual order of \(p\) and \(q\)
has no impact on the length of the proof search.

We proceed to relax the general task of finding a good precedence
to the task of finding a good pairwise preference function.
Once we have such function,
we will be interested in finding a precedence \(\pi_P\) that minimizes the cumulative preference value:

\begin{align*}
\CostProxy(\pi_P) = \sum_{p, q: \inv{\pi_P}(p) < \inv{\pi_P}(q)} \pref(p, q)
= \sum_{i, j} \OrderMatrix(\pi_P)_{i, j} \cdot \pref(p_i, p_j)
\end{align*}
\todo[author=Filip]{Is it not too confusing to have two expressions?}
\todo[author=Filip]{Shall we call it "surrogate loss"? Our proxy cost seems to be positively aligned with the conventional use of the term but typically "surrogate loss" is differentiable.}

While the problem of minimizing \(\CostProxy(\pi_P)\) given an arbitrary \(\pref\) is NP-hard,
a greedy 2-approximation algorithm exists.\cite{Cohen2011}
\todo[author=Filip]{Discuss: Is the algorithm acceptable despite the fact that it does not guarantee to find the optimum?}

Note that each of the precedence heuristics implemented in Vampire minimizes \(\CostProxy\)
for a particular \(\pref\).
\todo[author=Filip]{Discuss in more detail.}
\todo[inline,author=Filip]{Do we really cover all Vampire heuristics? How about \texttt{occurrence}, \texttt{scramble}, \texttt{weighted\_frequency}, \texttt{reverse\_weighted\_frequency}? What about \texttt{--symbol\_precedence\_boost}?}

\subsection{Preference learning as supervised machine learning}

In order to cast the problem of finding an appropriate \(\pref\) function
as a supervised machine learning task,
and to know preference values for pairs of symbols in the training set.

\subsubsection{Target preference values}
\label{sec:target-preference-values}

For each problem in the training set, we construct a preference matrix that contains a preference
value estimate for each pair of symbols in the problem.
\todo[inline,author=Filip]{Why do we do this? Why don't we just take \(\CostStd\) as the target value? My intuition is that this way we get less variance in the target values. Our approach also possibly enables (or improves) sample weighting by absolute value of \(\pref\). I think we originally chose to use lasso because on a fixed problem lasso outperforms "MeanRegression" -- lasso generalizes better. But we could alternatively rely on regularization in the outer regression! We would probably need more samples to train the outer regression, but the model simplicity and saving time to train the inner regressors may be worth it.}
We populate the matrix by the weights of a linear model trained on data
collected from a number of \gls{atp} runs on uniformly random precedences.
Each training sample has the following structure:

\begin{itemize}
	\item Input: \(\flatten{\OrderMatrix(\pi_P)}\) --
	flattened \gls{order-matrix} of a precedence \(\pi_P\)
	\item Target: \(\CostStd(\pi_P)\) --
	standardized result of an \gls{atp} run on problem \(P\) with predicate precedence \(\pi_P\)
	as defined in \autoref{sec:precedence-valuation}
\end{itemize}

This way we ensure that the preference matrix has a high value for a symbol pair \(l, r\)
if the precedences that order \(l\) before \(r\) have a high expected cost.

We use lasso regression \cite{?} to train the model.
Advantages of using lasso as opposed to standard linear regression\cite{?}:

\begin{itemize}
	\item Lasso implements regularization so it generalizes to unseen data better.
	\item Lasso prefers zero-valued weights so it is more likely to declare that the mutual order of a pair of symbols does not matter.
	\todo[author=Filip]{I think we should use RidgeCV or ElasticNetCV instead because they minimize L2 norm, while lasso only minimizes L1 norm.}
\end{itemize}

To ensure good generalization,
we use cross-validation as implemented in sklearn.linear\_model.LassoCV \cite{?}
to set the regularization parameter.
Note that each problem may use a different value of the regularization parameter.
\todo[inline,author=Filip]{Don't we need to use the same value of regularization parameter in order for the preference matrix values to be comparable across problems?}

\subsubsection{Symbol pair embedding}

We represent each predicate symbol by a feature vector that consists of the following features:

\begin{itemize}
	\item Arity
	\item Usage count
	\item Unit usage count
	\item In goal
	\item In unit
\end{itemize}\todo[author=Filip]{Explain the meaning of each of these features.}

This choice is motivated by the fact that the values of all of these symbol properties
are readily available in the \gls{atp} Vampire
and that they suffice as a basis for all of the common symbol precedence heuristics.
\todo[author=Filip]{Claify more.}

We represent a pair of symbols \(l, r\) by the concatenation of their feature vectors.
\todo[inline,author=Filip]{Shall we remove problem embedding from the experiment for simplicity? I have omitted problem embedding in this text.}

\subsubsection{Generalized preference regressor}

Generalized preference regressor is trained on samples of the following structure:

\begin{itemize}
	\item Input: Embedding of a symbol pair \(p, q\) in problem \(P\)
	\item Target: \(\pref(p, q)\) -- an element of the preference matrix we learned for problem \(P\)
\end{itemize}

\subsubsection{Sample weighting}

We sample problem \(P\) from the training problem set with uniform probability.
\todo[author=Filip]{Actually we immediately exclude problems whose preference matrix is all-zero.}

Thanks to how \(\pref\) is constructed (see \autoref{sec:target-preference-values}),
preference values close to 0 are associated with symbol pairs whose mutual order has little effect
on the outcome of the proof search.
To focus the training on the symbol pairs whose order matters,
we weight the samples by the absolute target value.
Experiments show that training with ElasticNet without sample weighting
collapses to assigning zero coefficients to all features,
preventing any predictive capacity.
\todo[author=Filip]{Is it ok to mention an experimental result in this section like this?}

% Result data file: sftp://cluster.ciirc.cvut.cz/home/bartefil/git/vampire-ml/map-reduce/predicate-100-1000/2020-05-08_20-49-14/reduce/fit_cv_results.csv
% Rows where params is {} or {weighted: False} show impact of sample weighting (both problem and symbol pair).
% Disabling weighting leads to collapse of fitted coefficients, as demonstrated in feature_weights.csv.

\todo[inline,author=Filip]{Will we use problem weighting after all? It is more difficult to justify...}

\subsection{Precedence construction}

When presented a new problem, we construct a predicate precedence by
first evaluating the generalized preference regressor for all pairs of predicates,
and then using greedy algorithm to construct the precedence using these predicted preference values.

In this manner we find a \(\pi_P\) that approximately minimizes \(\CostProxy(\pi_P)\).

\section{Evaluation}
\label{sec:evaluation}

\subsection{Setup}

For evaluation of the system presented in \autoref{sec:architecture},
we use TPTP v7.2.0 \cite{?}, a collection of problems.
From TPTP we select test set \(\ProblemsTest\) of 15751 problems with the following properties:

\begin{itemize}
	\item \gls{fol} or \gls{cnf} problem
	\item At most 1024 predicate symbols
\end{itemize}
% problems/predicate-small-1024.txt

We restrict training to sample problems from a set
\(\ProblemsTrain \subset \ProblemsTest\) of 201 problems
with the following properties:

\begin{itemize}
	\item At least 12 out of 24 random precedences solve the problem successfully.
	\item The distribution of saturation iteration counts on 24 random precedences
	shows variation of at least 1.
\end{itemize}
% problems/predicate-easy-variation.txt

We train the system on 100 problems uniformly sampled from \(\ProblemsTrain\)
and test the system on 1000 problems uniformly sampled from \(\ProblemsTest\)
excluding the problems sampled for training.

On each training problem we run the \gls{atp} Vampire with 1000 uniformly random predicate precedences
and with the following options:

\begin{lstlisting}[language=sh]
--literal_comparison_mode predicate
--symbol_precedence frequency
--saturation_algorithm discount
--age_weight_ratio 10
--avatar off
--time_limit 10
--memory_limit 8192
\end{lstlisting}

Note that we use a customized version of Vampire to extract a symbol table from each problem.
We call it with the same parameters, adding \texttt{--mode clausify}.
\todo[author=Filip]{Add a link to our custom version of Vampire.}

After we fit a preference matrix to each of the training problems,
we create a batch of 1000000 symbol pairs with target values
to train the main generalized preference regressor.

\todo[inline,author=Filip]{Add a link to the repo with the experiment code.}

\subsection{Results}

\subsubsection{Performance}

\begin{tabular}{lrrr}
	Case & Success rate & Better than frequency & Worse than frequency \\
	\hline
	Best of 10 random precedences & 0.513 & 0.029 & 0.006 \\
	Frequency heuristic & 0.490 & 0.000 & 0.000 \\
	GradientBoostingRegressor & 0.484 & 0.022 & 0.028 \\
	ElasticNetCV & 0.478 & 0.005 & 0.017 \\
	ElasticNetCV (no weighting) & 0.466 & 0.008 & 0.032 \\
	Random & 0.449 & 0.010 & 0.051 \\
\end{tabular}
% Source: sftp://cluster.ciirc.cvut.cz/home/bartefil/git/vampire-ml/map-reduce/predicate-100-1000/2020-05-08_20-49-14/reduce/fit_cv_results.csv

\todo[inline,author=Filip]{Describe the results.}

\subsubsection{Feature weights}

\todo[inline,author=Filip]{Shall we include a feature weight vector of ElasticNetCV?}

\section{Conclusion}

\todo[inline]{Finish.}

\glsaddall
\printglossaries

\bibliographystyle{plainnat}
\bibliography{main}

\end{document}
